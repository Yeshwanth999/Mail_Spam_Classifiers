{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15cb2f0-8e5d-4f7c-9539-d6636d42e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ykond\\anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import pdb\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "import pyswarms as ps\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tpot import TPOTClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b96f593-05c7-4e8c-9248-83df8838d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning models\n",
    "vectorizer=CountVectorizer(stop_words='english',lowercase=True)\n",
    "MNBC=MultinomialNB(alpha=0.5743650,class_prior=None,fit_prior=False)    #Multinomial Naive BAYES\n",
    "SGDC=SGDClassifier(loss=\"hinge\", alpha=0.0001, max_iter=1000, tol=1e-3, epsilon=0.1)   #Stochastic Gradient Descent\n",
    "DTC=tree.DecisionTreeClassifier(criterion = \"entropy\", splitter = \"best\")  #entropy can also be used  #Decision Tree\n",
    "RFC=RandomForestClassifier(criterion = \"entropy\")  #entropy must be used after gini    #Random Forest\n",
    "MLPC=MLPClassifier(hidden_layer_sizes=5,max_iter=10000,solver='lbfgs')  #Multi-layer Perceptron\n",
    "ABC=AdaBoostClassifier(n_estimators=100)          #AdaBoost Classifier\n",
    "GBC=GradientBoostingClassifier(n_estimators=100)        #GradientBoosting Classifier\n",
    "skf=StratifiedKFold(n_splits=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801995ba-ed0a-4753-849f-a94917174dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path=os.path.join(root, filename)\n",
    "            lines=[]\n",
    "            f=io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                lines.append(line)\n",
    "            f.close\n",
    "            message='\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows=[]\n",
    "    index=[]\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message':message, 'class':classification})\n",
    "        index.append(filename)\n",
    "    return pd.DataFrame(rows, index=index)\n",
    "\n",
    "data=pd.DataFrame({'message':[], 'class':[]})\n",
    "\n",
    "data=data.append(dataFrameFromDirectory('D:/Major Project/App_Data_Set/Spam_Assassin_Dataset/Spam','Spam'))\n",
    "data=data.append(dataFrameFromDirectory('D:/Major Project/App_Data_Set/Spam_Assassin_Dataset/Ham','Ham'))\n",
    "X=data['message']\n",
    "y=data['class']\n",
    "\n",
    "\n",
    "'''Pre-processing'''\n",
    "IDF = TfidfVectorizer().fit_transform(X)\n",
    "Tr_tokens=vectorizer.fit_transform(X)\n",
    "\n",
    "scores=np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce2f28e-f092-4f9f-9897-de5b88aefc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Stratified K_fold_Cross_Validation\n",
    "def SKF_Split(x):\n",
    "    skf=StratifiedKFold(n_splits=x,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1551d6e6-97dd-4a87-b0ad-0e63bdecd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Objective Funtions'''\n",
    "def MNB_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MNBC.fit(X_train, y_train)\n",
    "        lst.append(MNBC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def SGDC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        SGDC.fit(X_train, y_train)\n",
    "        lst.append(SGDC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def MLPC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MLPC.fit(X_train, y_train)\n",
    "        lst.append(MLPC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def DTC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        DTC.fit(X_train, y_train)\n",
    "        lst.append(DTC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def RFC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        RFC.fit(X_train, y_train)\n",
    "        lst.append(RFC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def GBC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        GBC.fit(X_train, y_train)\n",
    "        lst.append(GBC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def ABC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        ABC.fit(X_train, y_train)\n",
    "        lst.append(ABC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205c0802-cd14-4637-9799-929503e23e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classification functions'''\n",
    "#Multinomial Naive Bayes Calssification\n",
    "def MNB_Classification(alpha):\n",
    "    print(\"Multinomial Naive BAYES's Training and testing is running\")\n",
    "    MNBC.fit(X_train,y_train)\n",
    "    pred=MNBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = MNBC.score(X_train,y_train)*100, MNBC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "#Stochastic Gradient Descent (SGD) Calssification\n",
    "def SGDC_Classification(alpha,epsilon,tol):\n",
    "    print(\"Stochastic Gradient descent training and testing is running\")\n",
    "    SGDC.fit(X_train,y_train)\n",
    "    pred=SGDC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SGDC.score(X_train,y_train)*100, SGDC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "\n",
    "#Decision Tree Classification\n",
    "def DTC_Classification(max_depth,min_samples_leaf):\n",
    "    print(\"Decision Tree Classifier Training and testing is running\")\n",
    "    DTC.fit(X_train,y_train)\n",
    "    pred=DTC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = DTC.score(X_train,y_train)*100, DTC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest Classification\n",
    "def RFC_Classification(n_estimators,max_depth):\n",
    "    print(\"Random Forest Training and testing is running\")\n",
    "    RFC.fit(X_train,y_train)\n",
    "    pred=RFC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = RFC.score(X_train,y_train)*100, RFC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "\n",
    "#Multi-layer Perceptron Calssification\n",
    "def MLPC_Classification(hidden_layer_sizes,alpha):\n",
    "    print(\"Multi-layer Perceptron Training and testing is running\")\n",
    "    MLPC.fit(X_train,y_train)\n",
    "    pred=MLPC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = MLPC.score(X_train,y_train)*100, MLPC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "\n",
    "#GradientBoost Classification\n",
    "def GBC_Classification(n_estimators, learning_rate):\n",
    "    print(\"Gradientboost Classifier Training and testing is running\")\n",
    "    GBC.fit(X_train, y_train)\n",
    "    pred=GBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = GBC.score(X_train, y_train)*100, GBC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "\n",
    "\n",
    "\n",
    "#AdaBoost Classification\n",
    "def ABC_Classification(n_estimators, learning_rate):\n",
    "    print(\"Adaboost Classifier Training and testing is running\")\n",
    "    ABC.fit(X_train, y_train)\n",
    "    pred=ABC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = ABC.score(X_train, y_train)*100, ABC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf2f680-df51-4475-baff-f23b423f9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 12:31:26,119 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.7, 'w': 0.9, 'n_estimators': [1, 1000], 'learning_rate': [0.001, 100]}\n",
      "pyswarms.single.global_best:   0%|                                                                               |0/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/89500545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mGBC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mPSO_GBC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/89500545.py\u001b[0m in \u001b[0;36mPSO_GBC\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Call an instance of PSO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalBestPSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGBC_objective_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyswarms\\single\\global_best.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;31m# Compute cost for current position and personal best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;31m# fmt: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_objective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbest_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbest_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_pbest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;31m# Set best_cost_yet_found for ftol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyswarms\\backend\\operators.py\u001b[0m in \u001b[0;36mcompute_objective_function\u001b[1;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         results = pool.map(\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/4006550094.py\u001b[0m in \u001b[0;36mGBC_objective_func\u001b[1;34m(scores)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTr_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTr_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    669\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    746\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1343\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Main PSO Functions'''\n",
    "def PSO_GBC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators': [1, 1000], 'learning_rate': [1e-3, 100]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(GBC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    learning_rate=pos[1]\n",
    "    return GBC_Classification(n_estimators, learning_rate)\n",
    "PSO_GBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6895944-60f2-44bf-b4ff-1bb9ec1dc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_ABC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators': [1, 1000], 'learning_rate': [1e-3, 100]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(ABC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    learning_rate=pos[1]\n",
    "    return ABC_Classification(n_estimators, learning_rate)\n",
    "PSO_ABC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d647b982-5ac0-44d3-8c28-705491f8d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_MNB():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'alpha': [1e-3, 1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=1, options=options)\n",
    "    cost, pos=optimizer.optimize(MNB_objective_func, iters=100)\n",
    "    alpha=pos[0]\n",
    "    return MNB_Classification(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad07dca-97ed-470a-bc58-f83c7dcd7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_SGDC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'alpha':[0.0001,1000],'epsilon':[0.0001,1000],'tol':[.0001,1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=3, options=options)\n",
    "    cost, pos=optimizer.optimize(SGDC_objective_func, iters=100)\n",
    "    alpha=pos[0]\n",
    "    epsilon=pos[1]\n",
    "    tol=pos[2]\n",
    "    return SGDC_Classification(alpha,epsilon,tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461888d4-2ac5-42c1-8a9f-4c80c4025991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_MLPC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'hidden_layer_sizes':[5,100],'alpha':[0.0001,1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(MLPC_objective_func, iters=100)\n",
    "    hidden_layer_sizes=pos[0]\n",
    "    alpha=pos[1]\n",
    "    return MLPC_Classification(hidden_layer_sizes,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd6f908-557e-4123-9d3c-d06aa6800a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_DTC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9,'max_depth':[1,20],'min_samples_leaf':2}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(DTC_objective_func, iters=100)\n",
    "    max_depth=pos[0]\n",
    "    min_samples_leaf=pos[1]\n",
    "    return DTC_Classification(max_depth,min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78813eb8-738a-4a72-af4b-46c7d7766d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_RFC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators':[1,40],'max_depth':[1,20]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(RFC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    max_depth=pos[1]\n",
    "    return RFC_Classification(n_estimators,max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa09d3e-594e-48b6-a314-46995c0dace1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SKF_Split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1876/2019406830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mResult_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mMain_PSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1876/2019406830.py\u001b[0m in \u001b[0;36mMain_PSO\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMain_PSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mSKF_Split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0macc1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPSO_MNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0macc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPSO_SGDC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SKF_Split' is not defined"
     ]
    }
   ],
   "source": [
    "def Main_PSO():\n",
    "    \n",
    "    SKF_Split(4)\n",
    "    acc1=PSO_MNB()\n",
    "    acc2=PSO_SGDC()\n",
    "    acc3=PSO_DTC()\n",
    "    acc4=PSO_RFC()\n",
    "    acc5=PSO_MLPC()\n",
    "    acc6=PSO_GBC()\n",
    "    acc7=PSO_ABC()\n",
    "    \n",
    "        \n",
    "    Accuracy_Table=[('Stochastic Gradient Descent',acc2[0],acc2[1],acc2[2],acc2[3]),\n",
    "                ('Multinomial Naive BAYES',acc1[0],acc1[1],acc1[2],acc1[3]),\n",
    "                ('Random Forest',acc4[0],acc4[1],acc4[2],acc4[3]),\n",
    "                ('Decision Tree',acc3[0],acc3[1],acc3[2],acc3[3]),\n",
    "                ('Multi-later Perceptron',acc5[0],acc5[1],acc5[2],acc5[3]),\n",
    "                ('Gradient Boost Classifier',acc6[0],acc6[1],acc6[2],acc6[3]),\n",
    "                ('Adaboost Classifier',acc7[0],acc7[1],acc7[2],acc7[3])\n",
    "               ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"Testing Accuracy\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [acc1[0],acc1[1],acc1[2],acc1[3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [acc2[0],acc2[1],acc2[2],acc2[3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [acc3[0],acc3[1],acc3[2],acc3[3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [acc4[0],acc4[1],acc4[2],acc4[3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [acc5[0],acc5[1],acc5[2],acc5[3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [acc6[0],acc6[1],acc6[2],acc6[3]]\n",
    "    bar6 = plt.bar(ind+width*5, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [acc7[0],acc7[1],acc7[2],acc7[3]]\n",
    "    bar7 = plt.bar(ind+width*6, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    return Result_table\n",
    "Main_PSO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169efc4-75f2-4e1d-aa26-e23858572a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f72fa0-5511-4550-b1c1-a35334c3d853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
