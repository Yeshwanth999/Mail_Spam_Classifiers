{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import pdb\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "import pyswarms as ps\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tpot import TPOTClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning models\n",
    "vectorizer=CountVectorizer(stop_words='english',lowercase=True)\n",
    "\n",
    "MNBC=MultinomialNB(alpha=0.5743650,class_prior=None,fit_prior=False)    #Multinomial Naive BAYES\n",
    "SGDC=SGDClassifier(loss=\"log_loss\", alpha=0.0001, max_iter=1000, tol=1e-3, epsilon=0.1)   #Stochastic Gradient Descent\n",
    "DTC=DecisionTreeClassifier(criterion = \"entropy\", splitter = \"best\")  #entropy can also be used  #Decision Tree\n",
    "RFC=RandomForestClassifier(criterion = \"entropy\")  #entropy must be used after gini    #Random Forest\n",
    "MLPC=MLPClassifier(hidden_layer_sizes=5,max_iter=10000,solver='lbfgs')  #Multi-layer Perceptron\n",
    "ABC=AdaBoostClassifier(n_estimators=100)          #AdaBoost Classifier\n",
    "GBC=GradientBoostingClassifier(n_estimators=100)        #GradientBoosting Classifier\n",
    "\n",
    "#Voting Ensemble Technique\n",
    "VCH=VotingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)],voting='hard')\n",
    "VCS=VotingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)],voting='soft')\n",
    "\n",
    "##Bagging Ensemble Technique\n",
    "BMNBC=BaggingClassifier(MNBC)\n",
    "BSGDC=BaggingClassifier(SGDC)\n",
    "BDTC=BaggingClassifier(DTC)\n",
    "BRFC=BaggingClassifier(RFC)\n",
    "BMLPC=BaggingClassifier(MLPC)\n",
    "BGBC=BaggingClassifier(GBC)\n",
    "BABC=BaggingClassifier(ABC)\n",
    "\n",
    "#Stacking Ensemble Technique\n",
    "SCMNBC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=MNBC)\n",
    "SCSGDC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=SGDC)\n",
    "SCDTC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=DTC)\n",
    "SCRFC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=RFC)\n",
    "SCMLPC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=MLPC)\n",
    "SCGBC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=GBC)\n",
    "SCABC=StackingClassifier([('MNBC',MNBC),('SGDC',SGDC),('DTC',DTC),('RFC',RFC),('MLPC',MLPC),('ABC',ABC),('GBC',GBC)], final_estimator=ABC)\n",
    "\n",
    "skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "models=[MNBC,SGDC,DTC,RFC,MLPC]\n",
    "split_list=[5,4,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path=os.path.join(root, filename)\n",
    "            lines=[]\n",
    "            f=io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                lines.append(line)\n",
    "            f.close\n",
    "            message='\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows=[]\n",
    "    index=[]\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message':message, 'class':classification})\n",
    "        index.append(filename)\n",
    "    return pd.DataFrame(rows, index=index)\n",
    "\n",
    "data=pd.DataFrame({'message':[], 'class':[]})\n",
    "\n",
    "data=data.append(dataFrameFromDirectory('D:/Major Project/App_Data_Set/Spam_Assassin_Dataset/Spam','Spam'))\n",
    "data=data.append(dataFrameFromDirectory('D:/Major Project/App_Data_Set/Spam_Assassin_Dataset/Ham','Ham'))\n",
    "X=data['message']\n",
    "y=data['class']\n",
    "\n",
    "\n",
    "'''Pre-processing'''\n",
    "IDF = TfidfVectorizer().fit_transform(X)\n",
    "Tr_tokens=vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "MNBC_accu_stratified=list()\n",
    "SGDC_accu_stratified=list()\n",
    "DTC_accu_stratified=list()\n",
    "RFC_accu_stratified=list()\n",
    "MPLC_accu_stratified=list()\n",
    "scores=np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Stratified K_fold_Cross_Validation\n",
    "def SKF_Split(x):\n",
    "    skf=StratifiedKFold(n_splits=x,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking is being applied for MNBC Classifier, Training and testing arerunning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.49804796430564, 98.28680203045685, 100.0, 99.136)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Stacking_MNBC_Classification():\n",
    "    print('Stacking is being applied for MNBC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCMNBC.fit(X_train, y_train)\n",
    "    pred=SCMNBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCMNBC.score(X_train,y_train)*100, SCMNBC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_MNBC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking is being applied for SGDC Classifier, Training and testing arerunning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.96281836772634, 99.87105093488073, 100.0, 99.93548387096774)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Stacking_SGDC_Classification():\n",
    "    print('Stacking is being applied for SGDC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCSGDC.fit(X_train, y_train)\n",
    "    pred=SCSGDC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCSGDC.score(X_train,y_train)*100, SCSGDC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_SGDC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking is being applied for DTC Classifier, Training and testing arerunning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15684/3320340273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mTraining_Accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTesting_Accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mTesting_Accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Spam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Spam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Spam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mStacking_DTC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15684/3320340273.py\u001b[0m in \u001b[0;36mStacking_DTC_Classification\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacking is being applied for DTC Classifier, Training and testing arerunning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSKF_Split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mTraining_Accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTesting_Accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             )\n\u001b[1;32m--> 232\u001b[1;33m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    233\u001b[0m                 delayed(cross_val_predict)(\n\u001b[0;32m    234\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m     predictions = parallel(\n\u001b[0m\u001b[0;32m    969\u001b[0m         delayed(_fit_and_predict)(\n\u001b[0;32m    970\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    669\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    746\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1343\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Stacking_DTC_Classification():\n",
    "    print('Stacking is being applied for DTC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCDTC.fit(X_train, y_train)\n",
    "    pred=SCDTC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCDTC.score(X_train,y_train)*100, SCDTC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_DTC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_RFC_Classification():\n",
    "    print('Stacking is being applied for RFC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCRFC.fit(X_train, y_train)\n",
    "    pred=SCRFC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCRFC.score(X_train,y_train)*100, SCRFC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_RFC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_MLPC_Classification():\n",
    "    print('Stacking is being applied for MLPC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCMLPC.fit(X_train, y_train)\n",
    "    pred=SCMLPC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCMLPC.score(X_train,y_train)*100, SCMLPC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_MLPC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_GBC_Classification():\n",
    "    print('Stacking is being applied for GBC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCGBC.fit(X_train, y_train)\n",
    "    pred=SCGBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCGBC.score(X_train,y_train)*100, SCGBC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_GBC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_ABC_Classification():\n",
    "    print('Stacking is being applied for ABC Classifier, Training and testing arerunning')\n",
    "    SKF_Split(4)\n",
    "    SCABC.fit(X_train, y_train)\n",
    "    pred=SCABC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SCABC.score(X_train,y_train)*100, SCABC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "Stacking_ABC_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCH Training and testing is running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.98140918386316, 100.0, 99.9354422207876, 99.96771068776236)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def VotingHard_Classification():\n",
    "    print('VCH Training and testing is running')\n",
    "    SKF_Split(4)\n",
    "    VCH.fit(X_train, y_train)\n",
    "    pred=VCH.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = VCH.score(X_train,y_train)*100, VCH.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "VotingHard_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCS Training and testing is running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100.0, 100.0, 100.0, 100.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def VotingSoft_Classification():\n",
    "    print('VCS Training and testing is running')\n",
    "    SKF_Split(4)\n",
    "    VCS.fit(X_train, y_train)\n",
    "    pred=VCS.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = VCS.score(X_train,y_train)*100, VCS.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "VotingSoft_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging MNB\n",
    "def BMNB_Classification():\n",
    "    print(\"Bagging classification of Multinomial Naive BAYES's Training and testing is running\")\n",
    "    BMNBC.fit(X_train,y_train)\n",
    "    pred=BMNBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BMNBC.score(X_train,y_train)*100, BMNBC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging GBC\n",
    "def BGBC_Classification():\n",
    "    print(\"Bagging classification of Gradientboost Classifier Training and testing is running\")\n",
    "    BGBC.fit(X_train, y_train)\n",
    "    pred=BGBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BGBC.score(X_train, y_train)*100, BGBC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost Classification\n",
    "def BABC_Classification():\n",
    "    print(\"Bagging classification of Adaboost Classifier Training and testing is running\")\n",
    "    BABC.fit(X_train, y_train)\n",
    "    pred=BABC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BABC.score(X_train, y_train)*100, BABC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD) Calssification\n",
    "def BSGDC_Classification():\n",
    "    print(\"Bagging classification of Stochastic Gradient descent training and testing is running\")\n",
    "    BSGDC.fit(X_train,y_train)\n",
    "    pred=BSGDC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BSGDC.score(X_train,y_train)*100, BSGDC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classification\n",
    "def BDTC_Classification():\n",
    "    print(\"Bagging classification of Decision Tree Classifier Training and testing is running\")\n",
    "    BDTC.fit(X_train,y_train)\n",
    "    pred=BDTC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BDTC.score(X_train,y_train)*100, BDTC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "def BRFC_Classification():\n",
    "    print(\"Bagging classification of Random Forest Training and testing is running\")\n",
    "    BRFC.fit(X_train,y_train)\n",
    "    pred=BRFC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BRFC.score(X_train,y_train)*100, BRFC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-layer Perceptron Calssification\n",
    "def BMLPC_Classification():\n",
    "    print(\"Bagging classification of Multi-layer Perceptron Training and testing is running\")\n",
    "    BMLPC.fit(X_train,y_train)\n",
    "    pred=BMLPC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = BMLPC.score(X_train,y_train)*100, BMLPC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes Calssification\n",
    "def MNB_Classification(alpha):\n",
    "    print(\"Multinomial Naive BAYES's Training and testing is running\")\n",
    "    MNBC.fit(X_train,y_train)\n",
    "    pred=MNBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = MNBC.score(X_train,y_train)*100, MNBC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoost Classification\n",
    "def GBC_Classification(n_estimators, learning_rate):\n",
    "    print(\"Gradientboost Classifier Training and testing is running\")\n",
    "    GBC.fit(X_train, y_train)\n",
    "    pred=GBC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = GBC.score(X_train, y_train)*100, GBC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost Classification\n",
    "def ABC_Classification(n_estimators, learning_rate):\n",
    "    print(\"Adaboost Classifier Training and testing is running\")\n",
    "    ABC.fit(X_train, y_train)\n",
    "    pred=ABC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = ABC.score(X_train, y_train)*100, ABC.score(X_test, y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD) Calssification\n",
    "def SGDC_Classification(alpha,epsilon,tol):\n",
    "    print(\"Stochastic Gradient descent training and testing is running\")\n",
    "    SGDC.fit(X_train,y_train)\n",
    "    pred=SGDC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = SGDC.score(X_train,y_train)*100, SGDC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classification\n",
    "def DTC_Classification(max_depth,min_samples_leaf):\n",
    "    print(\"Decision Tree Classifier Training and testing is running\")\n",
    "    DTC.fit(X_train,y_train)\n",
    "    pred=DTC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = DTC.score(X_train,y_train)*100, DTC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "def RFC_Classification(n_estimators,max_depth):\n",
    "    print(\"Random Forest Training and testing is running\")\n",
    "    RFC.fit(X_train,y_train)\n",
    "    pred=RFC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = RFC.score(X_train,y_train)*100, RFC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-layer Perceptron Calssification\n",
    "def MLPC_Classification(hidden_layer_sizes,alpha):\n",
    "    print(\"Multi-layer Perceptron Training and testing is running\")\n",
    "    MLPC.fit(X_train,y_train)\n",
    "    pred=MLPC.predict(X_test)\n",
    "    Training_Accuracy, Testing_Accuracy = MLPC.score(X_train,y_train)*100, MLPC.score(X_test,y_test)*100\n",
    "    return Testing_Accuracy, (metrics.precision_score(y_test,pred,pos_label='Spam')*100), (metrics.recall_score(y_test,pred,pos_label='Spam')*100), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold has been applied for 5 Splits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MNB_Classification() missing 1 required positional argument: 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/3959699184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mResult_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[0mMain_Base_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/3959699184.py\u001b[0m in \u001b[0;36mMain_Base_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Stratified K-Fold has been applied for {} Splits\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mele\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mSKF_Split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mele\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0macc1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMNB_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0macc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGDC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0macc3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: MNB_Classification() missing 1 required positional argument: 'alpha'"
     ]
    }
   ],
   "source": [
    "def Main_Base_model():\n",
    "    MNB_ACC_LST=list()\n",
    "    SGDC_ACC_LST=list()\n",
    "    DTC_ACC_LST=list()\n",
    "    RFC_ACC_LST=list()\n",
    "    MLPC_ACC_LST=list()\n",
    "    GBC_ACC_LST=list()\n",
    "    ABC_ACC_LST=list()\n",
    "    \n",
    "    for ele in split_list:\n",
    "        print(\"Stratified K-Fold has been applied for {} Splits\".format(ele))\n",
    "        SKF_Split(ele)\n",
    "        acc1=MNB_Classification()\n",
    "        acc2=SGDC_Classification()\n",
    "        acc3=DTC_Classification()\n",
    "        acc4=RFC_Classification()\n",
    "        acc5=MLPC_Classification()\n",
    "        acc6=GBC_Classification()\n",
    "        acc7=ABC_Classification()\n",
    "        MNB_ACC_LST.append(acc1*100)\n",
    "        SGDC_ACC_LST.append(acc2*100)\n",
    "        DTC_ACC_LST.append(acc3*100)\n",
    "        RFC_ACC_LST.append(acc4*100)\n",
    "        MLPC_ACC_LST.append(acc5*100)\n",
    "        GBC_ACC_LST.append(acc6*100)\n",
    "        ABC_ACC_LST.append(acc7*100)\n",
    "        \n",
    "    Accuracy_Table=[('Stochastic Gradient Descent',SGDC_ACC_LST[0][0],SGDC_ACC_LST[0][1],SGDC_ACC_LST[0][2],SGDC_ACC_LST[0][3],SGDC_ACC_LST[1][0],SGDC_ACC_LST[1][1],SGDC_ACC_LST[1][2],SGDC_ACC_LST[1][3],SGDC_ACC_LST[2][0],SGDC_ACC_LST[2][1],SGDC_ACC_LST[2][2],SGDC_ACC_LST[2][3],SGDC_ACC_LST[3][0],SGDC_ACC_LST[3][1],SGDC_ACC_LST[3][2],SGDC_ACC_LST[3][3]),\n",
    "                ('Multinomial Naive BAYES',MNB_ACC_LST[0][0],MNB_ACC_LST[0][1],MNB_ACC_LST[0][2],MNB_ACC_LST[0][3],MNB_ACC_LST[1][0],MNB_ACC_LST[1][1],MNB_ACC_LST[1][2],MNB_ACC_LST[1][3],MNB_ACC_LST[2][0],MNB_ACC_LST[2][1],MNB_ACC_LST[2][2],MNB_ACC_LST[2][3],MNB_ACC_LST[3][0],MNB_ACC_LST[3][1],MNB_ACC_LST[3][2],MNB_ACC_LST[3][3]),\n",
    "                ('Random Forest',RFC_ACC_LST[0][0],RFC_ACC_LST[0][1],RFC_ACC_LST[0][2],RFC_ACC_LST[0][3],RFC_ACC_LST[1][0],RFC_ACC_LST[1][1],RFC_ACC_LST[1][2],RFC_ACC_LST[1][3],RFC_ACC_LST[2][0],RFC_ACC_LST[2][1],RFC_ACC_LST[2][2],RFC_ACC_LST[2][3],RFC_ACC_LST[3][0],RFC_ACC_LST[3][1],RFC_ACC_LST[3][2],RFC_ACC_LST[3][3]),\n",
    "                ('Decision Tree',DTC_ACC_LST[0][0],DTC_ACC_LST[0][1],DTC_ACC_LST[0][2],DTC_ACC_LST[0][3],DTC_ACC_LST[1][0],DTC_ACC_LST[1][1],DTC_ACC_LST[1][2],DTC_ACC_LST[1][3],DTC_ACC_LST[2][0],DTC_ACC_LST[2][1],DTC_ACC_LST[2][2],DTC_ACC_LST[2][3],DTC_ACC_LST[3][0],DTC_ACC_LST[3][1],DTC_ACC_LST[3][2],DTC_ACC_LST[3][3]),\n",
    "                ('Multi-later Perceptron',MLPC_ACC_LST[0][0],MLPC_ACC_LST[0][1],MLPC_ACC_LST[0][2],MLPC_ACC_LST[0][3],MLPC_ACC_LST[1][0],MLPC_ACC_LST[1][1],MLPC_ACC_LST[1][2],MLPC_ACC_LST[1][3],MLPC_ACC_LST[2][0],MLPC_ACC_LST[2][1],MLPC_ACC_LST[2][2],MLPC_ACC_LST[2][3],MLPC_ACC_LST[3][0],MLPC_ACC_LST[3][1],MLPC_ACC_LST[3][2],MLPC_ACC_LST[3][3]),\n",
    "                ('GradientBoosting Classifier',GBC_ACC_LST[0][0],GBC_ACC_LST[0][1],GBC_ACC_LST[0][2],GBC_ACC_LST[0][3],GBC_ACC_LST[1][0],GBC_ACC_LST[1][1],GBC_ACC_LST[1][2],GBC_ACC_LST[1][3],GBC_ACC_LST[2][0],GBC_ACC_LST[2][1],GBC_ACC_LST[2][2],GBC_ACC_LST[2][3],GBC_ACC_LST[3][0],GBC_ACC_LST[3][1],GBC_ACC_LST[3][2],GBC_ACC_LST[3][3]),\n",
    "                ('AdaBoost Classifier',ABC_ACC_LST[0][0],ABC_ACC_LST[0][1],ABC_ACC_LST[0][2],ABC_ACC_LST[0][3],ABC_ACC_LST[1][0],ABC_ACC_LST[1][1],ABC_ACC_LST[1][2],ABC_ACC_LST[1][3],ABC_ACC_LST[2][0],ABC_ACC_LST[2][1],ABC_ACC_LST[2][2],ABC_ACC_LST[2][3],ABC_ACC_LST[3][0],ABC_ACC_LST[3][1],ABC_ACC_LST[3][2],ABC_ACC_LST[3][3])\n",
    "               ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"80-20 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"75-25 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"67-33 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"50-50 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    '''80-20 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [MNB_ACC_LST[0][0],MNB_ACC_LST[0][1],MNB_ACC_LST[0][2],MNB_ACC_LST[0][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [SGDC_ACC_LST[0][0],SGDC_ACC_LST[0][1],SGDC_ACC_LST[0][2],SGDC_ACC_LST[0][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [DTC_ACC_LST[0][0],DTC_ACC_LST[0][1],DTC_ACC_LST[0][2],DTC_ACC_LST[0][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [RFC_ACC_LST[0][0],RFC_ACC_LST[0][1],RFC_ACC_LST[0][2],RFC_ACC_LST[0][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [MLPC_ACC_LST[0][0],MLPC_ACC_LST[0][1],MLPC_ACC_LST[0][2],MLPC_ACC_LST[0][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [GBC_ACC_LST[0][0],GBC_ACC_LST[0][1],GBC_ACC_LST[0][2],GBC_ACC_LST[0][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [ABC_ACC_LST[0][0],ABC_ACC_LST[0][1],ABC_ACC_LST[0][2],ABC_ACC_LST[0][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 80-20 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    '''75-25 Split Accuracy Plot '''\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [MNB_ACC_LST[1][0],MNB_ACC_LST[1][1],MNB_ACC_LST[1][2],MNB_ACC_LST[1][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [SGDC_ACC_LST[1][0],SGDC_ACC_LST[1][1],SGDC_ACC_LST[1][2],SGDC_ACC_LST[1][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [DTC_ACC_LST[1][0],DTC_ACC_LST[1][1],DTC_ACC_LST[1][2],DTC_ACC_LST[1][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [RFC_ACC_LST[1][0],RFC_ACC_LST[1][1],RFC_ACC_LST[1][2],RFC_ACC_LST[1][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [MLPC_ACC_LST[1][0],MLPC_ACC_LST[1][1],MLPC_ACC_LST[1][2],MLPC_ACC_LST[1][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [GBC_ACC_LST[1][0],GBC_ACC_LST[1][1],GBC_ACC_LST[1][2],GBC_ACC_LST[1][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [ABC_ACC_LST[1][0],ABC_ACC_LST[1][1],ABC_ACC_LST[1][2],ABC_ACC_LST[1][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''67-33 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [MNB_ACC_LST[2][0],MNB_ACC_LST[2][1],MNB_ACC_LST[2][2],MNB_ACC_LST[2][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [SGDC_ACC_LST[2][0],SGDC_ACC_LST[2][1],SGDC_ACC_LST[2][2],SGDC_ACC_LST[2][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [DTC_ACC_LST[2][0],DTC_ACC_LST[2][1],DTC_ACC_LST[2][2],DTC_ACC_LST[2][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [RFC_ACC_LST[2][0],RFC_ACC_LST[2][1],RFC_ACC_LST[2][2],RFC_ACC_LST[2][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [MLPC_ACC_LST[2][1],MLPC_ACC_LST[2][1],MLPC_ACC_LST[2][2],MLPC_ACC_LST[2][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [GBC_ACC_LST[2][0],GBC_ACC_LST[2][1],GBC_ACC_LST[2][2],GBC_ACC_LST[2][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [ABC_ACC_LST[2][0],ABC_ACC_LST[2][1],ABC_ACC_LST[2][2],ABC_ACC_LST[2][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 67-33 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''50-50 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [MNB_ACC_LST[3][0],MNB_ACC_LST[3][1],MNB_ACC_LST[3][2],MNB_ACC_LST[3][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [SGDC_ACC_LST[3][0],SGDC_ACC_LST[3][1],SGDC_ACC_LST[3][2],SGDC_ACC_LST[3][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [DTC_ACC_LST[3][0],DTC_ACC_LST[3][1],DTC_ACC_LST[3][2],DTC_ACC_LST[3][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [RFC_ACC_LST[3][0],RFC_ACC_LST[3][1],RFC_ACC_LST[3][2],RFC_ACC_LST[3][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [MLPC_ACC_LST[3][1],MLPC_ACC_LST[3][1],MLPC_ACC_LST[3][2],MLPC_ACC_LST[3][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [GBC_ACC_LST[3][0],GBC_ACC_LST[3][1],GBC_ACC_LST[3][2],GBC_ACC_LST[3][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [ABC_ACC_LST[3][0],ABC_ACC_LST[3][1],ABC_ACC_LST[3][2],ABC_ACC_LST[3][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 50-50 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Result_table\n",
    "Main_Base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold has been applied for 5 Splits\n",
      "Bagging classification of Multinomial Naive BAYES's Training and testing is running\n",
      "Bagging classification of Stochastic Gradient descent training and testing is running\n",
      "Bagging classification of Decision Tree Classifier Training and testing is running\n",
      "Bagging classification of Random Forest Training and testing is running\n",
      "Bagging classification of Multi-layer Perceptron Training and testing is running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6200/1246365012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mResult_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m \u001b[0mMain_Bagging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6200/1246365012.py\u001b[0m in \u001b[0;36mMain_Bagging\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0macc3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBDTC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0macc4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBRFC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0macc5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBMLPC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0macc6\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBGBC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0macc7\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBABC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6200/2759282950.py\u001b[0m in \u001b[0;36mBMLPC_Classification\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mBMLPC_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bagging classification of Multi-layer Perceptron Training and testing is running\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mBMLPC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBMLPC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mTraining_Accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTesting_Accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBMLPC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBMLPC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         )\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_seeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         all_results = Parallel(\n\u001b[0m\u001b[0;32m    435\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mestimator_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             self._fit_lbfgs(\n\u001b[0m\u001b[0;32m    442\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    547\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_grad_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                   **options)\n\u001b[0;32m    622\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    625\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;31m# Forward propagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m# Get loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# Iterate over the hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvecs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0m\u001b[0;32m    492\u001b[0m            other.ravel(), result.ravel())\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Main_Bagging():\n",
    "    BMNB_ACC_LST=list()\n",
    "    BSGDC_ACC_LST=list()\n",
    "    BDTC_ACC_LST=list()\n",
    "    BRFC_ACC_LST=list()\n",
    "    BMLPC_ACC_LST=list()\n",
    "    BGBC_ACC_LST=list()\n",
    "    BABC_ACC_LST=list()\n",
    "    \n",
    "    for ele in split_list:\n",
    "        print(\"Stratified K-Fold has been applied for {} Splits\".format(ele))\n",
    "        SKF_Split(ele)\n",
    "        acc1=BMNB_Classification()\n",
    "        acc2=BSGDC_Classification()\n",
    "        acc3=BDTC_Classification()\n",
    "        acc4=BRFC_Classification()\n",
    "        acc5=BMLPC_Classification()\n",
    "        acc6=BGBC_Classification()\n",
    "        acc7=BABC_Classification()\n",
    "        BMNB_ACC_LST.append(acc1*100)\n",
    "        BSGDC_ACC_LST.append(acc2*100)\n",
    "        BDTC_ACC_LST.append(acc3*100)\n",
    "        BRFC_ACC_LST.append(acc4*100)\n",
    "        BMLPC_ACC_LST.append(acc5*100)\n",
    "        BGBC_ACC_LST.append(acc6*100)\n",
    "        BABC_ACC_LST.append(acc7*100)\n",
    "        \n",
    "    Accuracy_Table=[('Stochastic Gradient Descent',BSGDC_ACC_LST[0][0],BSGDC_ACC_LST[0][1],BSGDC_ACC_LST[0][2],BSGDC_ACC_LST[0][3],BSGDC_ACC_LST[1][0],BSGDC_ACC_LST[1][1],BSGDC_ACC_LST[1][2],BSGDC_ACC_LST[1][3],BSGDC_ACC_LST[2][0],BSGDC_ACC_LST[2][1],BSGDC_ACC_LST[2][2],BSGDC_ACC_LST[2][3],BSGDC_ACC_LST[3][0],BSGDC_ACC_LST[3][1],BSGDC_ACC_LST[3][2],BSGDC_ACC_LST[3][3]),\n",
    "                ('Multinomial Naive BAYES',BMNB_ACC_LST[0][0],BMNB_ACC_LST[0][1],BMNB_ACC_LST[0][2],BMNB_ACC_LST[0][3],BMNB_ACC_LST[1][0],BMNB_ACC_LST[1][1],BMNB_ACC_LST[1][2],BMNB_ACC_LST[1][3],BMNB_ACC_LST[2][0],BMNB_ACC_LST[2][1],BMNB_ACC_LST[2][2],BMNB_ACC_LST[2][3],BMNB_ACC_LST[3][0],BMNB_ACC_LST[3][1],BMNB_ACC_LST[3][2],BMNB_ACC_LST[3][3]),\n",
    "                ('Random Forest',BRFC_ACC_LST[0][0],BRFC_ACC_LST[0][1],BRFC_ACC_LST[0][2],BRFC_ACC_LST[0][3],BRFC_ACC_LST[1][0],BRFC_ACC_LST[1][1],BRFC_ACC_LST[1][2],BRFC_ACC_LST[1][3],BRFC_ACC_LST[2][0],BRFC_ACC_LST[2][1],BRFC_ACC_LST[2][2],BRFC_ACC_LST[2][3],BRFC_ACC_LST[3][0],BRFC_ACC_LST[3][1],BRFC_ACC_LST[3][2],BRFC_ACC_LST[3][3]),\n",
    "                ('Decision Tree',BDTC_ACC_LST[0][0],BDTC_ACC_LST[0][1],BDTC_ACC_LST[0][2],BDTC_ACC_LST[0][3],BDTC_ACC_LST[1][0],BDTC_ACC_LST[1][1],BDTC_ACC_LST[1][2],BDTC_ACC_LST[1][3],BDTC_ACC_LST[2][0],BDTC_ACC_LST[2][1],BDTC_ACC_LST[2][2],BDTC_ACC_LST[2][3],BDTC_ACC_LST[3][0],BDTC_ACC_LST[3][1],BDTC_ACC_LST[3][2],BDTC_ACC_LST[3][3]),\n",
    "                ('Multi-later Perceptron',BMLPC_ACC_LST[0][0],BMLPC_ACC_LST[0][1],BMLPC_ACC_LST[0][2],BMLPC_ACC_LST[0][3],BMLPC_ACC_LST[1][0],BMLPC_ACC_LST[1][1],BMLPC_ACC_LST[1][2],BMLPC_ACC_LST[1][3],BMLPC_ACC_LST[2][0],BMLPC_ACC_LST[2][1],BMLPC_ACC_LST[2][2],BMLPC_ACC_LST[2][3],BMLPC_ACC_LST[3][0],BMLPC_ACC_LST[3][1],BMLPC_ACC_LST[3][2],BMLPC_ACC_LST[3][3]),\n",
    "                ('GradientBoosting Classifier',BGBC_ACC_LST[0][0],BGBC_ACC_LST[0][1],BGBC_ACC_LST[0][2],BGBC_ACC_LST[0][3],BGBC_ACC_LST[1][0],BGBC_ACC_LST[1][1],BGBC_ACC_LST[1][2],BGBC_ACC_LST[1][3],BGBC_ACC_LST[2][0],BGBC_ACC_LST[2][1],BGBC_ACC_LST[2][2],BGBC_ACC_LST[2][3],BGBC_ACC_LST[3][0],BGBC_ACC_LST[3][1],BGBC_ACC_LST[3][2],BGBC_ACC_LST[3][3]),\n",
    "                ('AdaBoost Classifier',BABC_ACC_LST[0][0],BABC_ACC_LST[0][1],BABC_ACC_LST[0][2],BABC_ACC_LST[0][3],BABC_ACC_LST[1][0],BABC_ACC_LST[1][1],BABC_ACC_LST[1][2],BABC_ACC_LST[1][3],BABC_ACC_LST[2][0],BABC_ACC_LST[2][1],BABC_ACC_LST[2][2],BABC_ACC_LST[2][3],BABC_ACC_LST[3][0],BABC_ACC_LST[3][1],BABC_ACC_LST[3][2],BABC_ACC_LST[3][3])\n",
    "               ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"80-20 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"75-25 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"67-33 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\",\"50-50 Split\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    '''80-20 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [BMNB_ACC_LST[0][0],BMNB_ACC_LST[0][1],BMNB_ACC_LST[0][2],BMNB_ACC_LST[0][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [BSGDC_ACC_LST[0][0],BSGDC_ACC_LST[0][1],BSGDC_ACC_LST[0][2],BSGDC_ACC_LST[0][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [BDTC_ACC_LST[0][0],BDTC_ACC_LST[0][1],BDTC_ACC_LST[0][2],BDTC_ACC_LST[0][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [BRFC_ACC_LST[0][0],BRFC_ACC_LST[0][1],BRFC_ACC_LST[0][2],BRFC_ACC_LST[0][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [BMLPC_ACC_LST[0][0],BMLPC_ACC_LST[0][1],BMLPC_ACC_LST[0][2],BMLPC_ACC_LST[0][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [BGBC_ACC_LST[0][0],BGBC_ACC_LST[0][1],BGBC_ACC_LST[0][2],BGBC_ACC_LST[0][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [BABC_ACC_LST[0][0],BABC_ACC_LST[0][1],BABC_ACC_LST[0][2],BABC_ACC_LST[0][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 80-20 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('BMNB', 'BSGDC', 'BDTC', 'BRFC', 'BMLPC', 'BGBC', 'BABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    '''75-25 Split Accuracy Plot '''\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [BMNB_ACC_LST[1][0],BMNB_ACC_LST[1][1],BMNB_ACC_LST[1][2],BMNB_ACC_LST[1][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [BSGDC_ACC_LST[1][0],BSGDC_ACC_LST[1][1],BSGDC_ACC_LST[1][2],BSGDC_ACC_LST[1][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [BDTC_ACC_LST[1][0],BDTC_ACC_LST[1][1],BDTC_ACC_LST[1][2],BDTC_ACC_LST[1][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [BRFC_ACC_LST[1][0],BRFC_ACC_LST[1][1],BRFC_ACC_LST[1][2],BRFC_ACC_LST[1][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [BMLPC_ACC_LST[1][0],BMLPC_ACC_LST[1][1],BMLPC_ACC_LST[1][2],BMLPC_ACC_LST[1][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [BGBC_ACC_LST[1][0],BGBC_ACC_LST[1][1],BGBC_ACC_LST[1][2],BGBC_ACC_LST[1][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [BABC_ACC_LST[1][0],BABC_ACC_LST[1][1],BABC_ACC_LST[1][2],BABC_ACC_LST[1][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('BMNB', 'BSGDC', 'BDTC', 'BRFC', 'BMLPC', 'BGBC', 'BABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''67-33 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [BMNB_ACC_LST[2][0],BMNB_ACC_LST[2][1],BMNB_ACC_LST[2][2],BMNB_ACC_LST[2][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [BSGDC_ACC_LST[2][0],BSGDC_ACC_LST[2][1],BSGDC_ACC_LST[2][2],BSGDC_ACC_LST[2][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [BDTC_ACC_LST[2][0],BDTC_ACC_LST[2][1],BDTC_ACC_LST[2][2],BDTC_ACC_LST[2][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [BRFC_ACC_LST[2][0],BRFC_ACC_LST[2][1],BRFC_ACC_LST[2][2],BRFC_ACC_LST[2][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [BMLPC_ACC_LST[2][1],BMLPC_ACC_LST[2][1],BMLPC_ACC_LST[2][2],BMLPC_ACC_LST[2][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [BGBC_ACC_LST[2][0],BGBC_ACC_LST[2][1],BGBC_ACC_LST[2][2],BGBC_ACC_LST[2][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [BABC_ACC_LST[2][0],BABC_ACC_LST[2][1],BABC_ACC_LST[2][2],BABC_ACC_LST[2][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 67-33 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('BMNB', 'BSGDC', 'BDTC', 'BRFC', 'BMLPC', 'BGBC', 'BABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''50-50 Split Accuracy Plot '''\n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    MNB_vals = [BMNB_ACC_LST[3][0],BMNB_ACC_LST[3][1],BMNB_ACC_LST[3][2],BMNB_ACC_LST[3][3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [BSGDC_ACC_LST[3][0],BSGDC_ACC_LST[3][1],BSGDC_ACC_LST[3][2],BSGDC_ACC_LST[3][3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [BDTC_ACC_LST[3][0],BDTC_ACC_LST[3][1],BDTC_ACC_LST[3][2],BDTC_ACC_LST[3][3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [BRFC_ACC_LST[3][0],BRFC_ACC_LST[3][1],BRFC_ACC_LST[3][2],BRFC_ACC_LST[3][3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [BMLPC_ACC_LST[3][1],BMLPC_ACC_LST[3][1],BMLPC_ACC_LST[3][2],BMLPC_ACC_LST[3][3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [BGBC_ACC_LST[3][0],BGBC_ACC_LST[3][1],BGBC_ACC_LST[3][2],BGBC_ACC_LST[3][3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [BABC_ACC_LST[3][0],BABC_ACC_LST[3][1],BABC_ACC_LST[3][2],BABC_ACC_LST[3][3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 50-50 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('BMNB', 'BSGDC', 'BDTC', 'BRFC', 'BMLPC', 'BGBC', 'BABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Result_table\n",
    "Main_Bagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_VC():\n",
    "    \n",
    "    SKF_Split(4)\n",
    "    acc1=VotingHard_Classification()\n",
    "    acc2=VotingSoft_Classification()\n",
    "\n",
    "    \n",
    "        \n",
    "    Accuracy_Table=[('Voting Classification Soft',acc2[0],acc2[1],acc2[2],acc2[3]),\n",
    "                ('Voting Classification Hard',acc1[0],acc1[1],acc1[2],acc1[3]),\n",
    "               ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"Testing Accuracy\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.12\n",
    "\n",
    "    VCH_vals = [acc1[0],acc1[1],acc1[2],acc1[3]]\n",
    "    bar1 = plt.bar(ind, VCH_vals, width, color = 'r')\n",
    "\n",
    "    VCS_vals = [acc2[0],acc2[1],acc2[2],acc2[3]]\n",
    "    bar2 = plt.bar(ind+width, VCS_vals, width, color='g')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['TA', 'PS', 'RS', 'F1-S'])\n",
    "    plt.legend( (bar1, bar2), ('VCH','VCS') )\n",
    "    plt.show()\n",
    "    \n",
    "    return Result_table\n",
    "Main_VC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_MNB():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'alpha': [1e-3, 1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=1, options=options)\n",
    "    cost, pos=optimizer.optimize(MNB_objective_func, iters=3)\n",
    "    alpha=pos[0]\n",
    "    return MNB_Classification(alpha)\n",
    "def MNB_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MNBC.fit(X_train, y_train)\n",
    "        lst.append(MNBC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 14:43:26,541 - pyswarms.single.global_best - INFO - Optimize for 3 iters with {'c1': 0.5, 'c2': 0.7, 'w': 0.9, 'alpha': [0.0001, 1000], 'epsilon': [0.0001, 1000], 'tol': [0.0001, 1000]}\n",
      "pyswarms.single.global_best: 100%||3/3, best_cost=0.99\n",
      "2022-07-05 14:43:42,816 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9895910780669145, best pos: [0.41667681 0.37169552 1.09881713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient descent training and testing is running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.69325153374233, 99.35608499678042, 99.58050984188448, 99.46817082997582)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PSO_SGDC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'alpha':[0.0001,1000],'epsilon':[0.0001,1000],'tol':[.0001,1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=3, options=options)\n",
    "    cost, pos=optimizer.optimize(SGDC_objective_func, iters=100)\n",
    "    alpha=pos[0]\n",
    "    epsilon=pos[1]\n",
    "    tol=pos[2]\n",
    "    return SGDC_Classification(alpha,epsilon,tol)\n",
    "def SGDC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        SGDC.fit(X_train, y_train)\n",
    "        lst.append(SGDC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "PSO_SGDC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 14:47:32,252 - pyswarms.single.global_best - INFO - Optimize for 3 iters with {'c1': 0.5, 'c2': 0.7, 'w': 0.9, 'hidden_layer_sizes': [5, 100], 'alpha': [0.0001, 1000]}\n",
      "pyswarms.single.global_best: 100%||3/3, best_cost=0.995\n",
      "2022-07-05 14:59:23,573 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9951672862453531, best pos: [0.50924196 0.88529553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron Training and testing is running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.52593418851087, 99.2248062015504, 99.12875121006776, 99.1767554479419)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PSO_MLPC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'hidden_layer_sizes':[5,100],'alpha':[0.0001,1000]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(MLPC_objective_func, iters=100)\n",
    "    hidden_layer_sizes=pos[0]\n",
    "    alpha=pos[1]\n",
    "    return MLPC_Classification(hidden_layer_sizes,alpha)\n",
    "def MLPC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MLPC.fit(X_train, y_train)\n",
    "        lst.append(MLPC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "PSO_MLPC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 14:19:43,942 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.7, 'w': 0.9, 'max_depth': [1, 20], 'min_samples_leaf': 2}\n",
      "pyswarms.single.global_best:   9%|                                                        |9/100, best_cost=0.996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13220/2746334745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mPSO_DTC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13220/2746334745.py\u001b[0m in \u001b[0;36mPSO_DTC\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Call an instance of PSO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalBestPSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyswarms\\single\\global_best.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;31m# Compute cost for current position and personal best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;31m# fmt: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_objective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbest_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbest_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_pbest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;31m# Set best_cost_yet_found for ftol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyswarms\\backend\\operators.py\u001b[0m in \u001b[0;36mcompute_objective_function\u001b[1;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         results = pool.map(\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13220/2746334745.py\u001b[0m in \u001b[0;36mobjective_func\u001b[1;34m(scores)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTr_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTr_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \"\"\"\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    970\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def PSO_DTC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9,'max_depth':[1,20],'min_samples_leaf':2}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(DTC_objective_func, iters=100)\n",
    "    max_depth=pos[0]\n",
    "    min_samples_leaf=pos[1]\n",
    "    return DTC_Classification(max_depth,min_samples_leaf)\n",
    "def DTC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        DTC.fit(X_train, y_train)\n",
    "        lst.append(DTC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "PSO_DTC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_RFC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators':[1,40],'max_depth':[1,20]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(RFC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    max_depth=pos[1]\n",
    "    return RFC_Classification(n_estimators,max_depth)\n",
    "def RFC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        RFC.fit(X_train, y_train)\n",
    "        lst.append(RFC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores\n",
    "PSO_RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Main PSO Functions'''\n",
    "def PSO_GBC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators': [1, 1000], 'learning_rate': [1e-3, 100]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(GBC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    learning_rate=pos[1]\n",
    "    return GBC_Classification(n_estimators, learning_rate)\n",
    "def GBC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        GBC.fit(X_train, y_train)\n",
    "        lst.append(GBC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_ABC():\n",
    "    n_particles=10\n",
    "    options = {'c1': 0.5, 'c2': 0.7, 'w':0.9, 'n_estimators': [1, 1000], 'learning_rate': [1e-3, 100]}\n",
    "    # Call an instance of PSO\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2, options=options)\n",
    "    cost, pos=optimizer.optimize(ABC_objective_func, iters=100)\n",
    "    n_estimators=pos[0]\n",
    "    learning_rate=pos[1]\n",
    "    return ABC_Classification(n_estimators, learning_rate)\n",
    "def ABC_objective_func(scores):\n",
    "    lst=[]\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    for i in range(10):\n",
    "        train_index, test_index = next(iter(skf.split(Tr_tokens,y)))\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        ABC.fit(X_train, y_train)\n",
    "        lst.append(ABC.score(X_test, y_test))\n",
    "        scores=np.array(lst)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 15:38:07,060 - pyswarms.single.global_best - INFO - Optimize for 3 iters with {'c1': 0.5, 'c2': 0.7, 'w': 0.9, 'alpha': [0.001, 1000]}\n",
      "pyswarms.single.global_best: 100%||3/3, best_cost=0.983\n",
      "2022-07-05 15:38:11,031 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.9825278810408922, best pos: [0.10625222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive BAYES's Training and testing is running\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/1188794086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"80-20 Split\",\"75-25 Split\",\"67-33 Split\",\"50-50 Split\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# return Result_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mMain_PSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5268/1188794086.py\u001b[0m in \u001b[0;36mMain_PSO\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# acc4=PSO_RFC()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# acc5=PSO_MLPC()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def Main_PSO():\n",
    "    \n",
    "    SKF_Split(4)\n",
    "    acc1=PSO_MNB()\n",
    "    acc2=PSO_SGDC()\n",
    "    acc3=PSO_DTC()\n",
    "    acc4=PSO_RFC()\n",
    "    acc5=PSO_MLPC()\n",
    "    acc6=PSO_GBC()\n",
    "    acc7=PSO_ABC()\n",
    "    \n",
    "        \n",
    "    Accuracy_Table=[('Stochastic Gradient Descent',acc2[0],acc2[1],acc2[2],acc2[3]),\n",
    "                ('Multinomial Naive BAYES',acc1[0],acc1[1],acc1[2],acc1[3]),\n",
    "                ('Random Forest',acc4[0],acc4[1],acc4[2],acc4[3]),\n",
    "                ('Decision Tree',acc3[0],acc3[1],acc3[2],acc3[3]),\n",
    "                ('Multi-later Perceptron',acc5[0],acc5[1],acc5[2],acc5[3]),\n",
    "                ('Gradient Boost Classifier',acc6[0],acc6[1],acc6[2],acc6[3]),\n",
    "                ('Adaboost Classifier',acc7[0],acc7[1],acc7[2],acc7[3])\n",
    "               ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"Testing Accuracy\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.18\n",
    "\n",
    "    MNB_vals = [acc1[0],acc1[1],acc1[2],acc1[3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [acc2[0],acc2[1],acc2[2],acc2[3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [acc3[0],acc3[1],acc3[2],acc3[3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [acc4[0],acc4[1],acc4[2],acc4[3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [acc5[0],acc5[1],acc5[2],acc5[3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [acc6[0],acc6[1],acc6[2],acc6[3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [acc7[0],acc7[1],acc7[2],acc7[3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    return Result_table\n",
    "Main_PSO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Since the input matrix is a sparse matrix, please makes sure all the operators in the customized config dictionary supports sparse matriies.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9926259768396226\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9926259768396226\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9926259768396226\n",
      "\n",
      "Best pipeline: MultinomialNB(input_matrix, alpha=0.001, fit_prior=True)\n",
      "Warning: Since the input matrix is a sparse matrix, please makes sure all the operators in the customized config dictionary supports sparse matriies.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9959100204498977, 0.9954574951330305, 0.9903163331181407, 99.28802588996763)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GA_MNB():\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tpot_config = {'sklearn.naive_bayes.MultinomialNB': {'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],'fit_prior': [True, False]}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2,config_dict=tpot_config,offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "GA_MNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Since the input matrix is a sparse matrix, please makes sure all the operators in the customized config dictionary supports sparse matriies.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9edd0eab69e43c59e824f0d5ccfa830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/240 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def GA_DTC():\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tpot_config = {'sklearn.tree.DecisionTreeClassifier': {'criterion': [\"gini\", \"entropy\"],'max_depth': range(1, 11),'min_samples_split': range(2, 21),'min_samples_leaf': range(1, 21)}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2,config_dict=tpot_config,offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "GA_DTC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_RFC():\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tpot_config = {'sklearn.ensemble.RandomForestClassifier': {'n_estimators': [100],'criterion': [\"gini\", \"entropy\"],'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                                                               'min_samples_split': range(2, 21),'min_samples_leaf':  range(1, 21),'bootstrap': [True, False]}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2,config_dict=tpot_config,offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "GA_RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_SGDC():\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tpot_config = {'sklearn.linear_model.SGDClassifier': {'loss': ['log', 'hinge', 'modified_huber', 'squared_hinge', 'perceptron'],'penalty': ['elasticnet'],'alpha': [0.0, 0.01, 0.001],\n",
    "                                                          'learning_rate': ['invscaling', 'constant'],'fit_intercept': [True, False],'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],'eta0': [0.1, 1.0, 0.01],\n",
    "                                                          'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2,config_dict=tpot_config,offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "GA_SGDC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_MLPC():\n",
    "    skf=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(Tr_tokens,y):\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tpot_config = {'sklearn.neural_network.MLPClassifier': {'alpha': [1e-4, 1e-3, 1e-2, 1e-1],'learning_rate_init': [1e-3, 1e-2, 1e-1, 0.5, 1.]}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2,config_dict=tpot_config,offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)\n",
    "GA_MLPC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_GBC():\n",
    "    SKF_Split(4)\n",
    "    tpot_config = {'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05)}}\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2, config_dict=tpot_config, offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_ABC():\n",
    "    SKF_Split(4)\n",
    "    tpot_config = {'sklearn.ensemble.AdaBoostClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.0]}}\n",
    "    \n",
    "    tpot = TPOTClassifier(generations=10, population_size=40, verbosity=2, config_dict=tpot_config, offspring_size=20)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    pred=tpot.predict(X_test)\n",
    "    return metrics.accuracy_score(pred, y_test), metrics.precision_score(y_test,pred,pos_label='Spam'), metrics.recall_score(y_test,pred,pos_label='Spam'), (metrics.f1_score(y_test, pred, pos_label='Spam')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_GA():\n",
    "    \n",
    "    acc1=GA_MNB()\n",
    "    acc2=GA_SGDC()\n",
    "    acc3=GA_DTC()\n",
    "    acc4=GA_RFC()\n",
    "    acc5=GA_MLPC()\n",
    "    acc6=GA_GBC()\n",
    "    acc7=GA_ABC()\n",
    "    \n",
    "    \n",
    "    Accuracy_Table=[('Stochastic Gradient Descent',acc2[0],acc2[1],acc2[2],acc2[3]),\n",
    "            ('Multinomial Naive BAYES',acc1[0],acc1[1],acc1[2],acc1[3]),\n",
    "            ('Random Forest',acc4[0],acc4[1],acc4[2],acc4[3]),\n",
    "            ('Decision Tree',acc3[0],acc3[1],acc3[2],acc3[3]),\n",
    "            ('Multi-later Perceptron',acc5[0],acc5[1],acc5[2],acc5[3]),\n",
    "            ('Gradient Boost Classifier',acc6[0],acc6[1],acc6[2],acc6[3]),\n",
    "            ('Adaboost Classifier',acc7[0],acc7[1],acc7[2],acc7[3])\n",
    "           ]\n",
    "    Result_table=pd.DataFrame(Accuracy_Table,columns=[\"Classifier\",\"Testing Accuracy\",\"Precision Score\",\"Recall Score\",\"F1-Score\"])\n",
    "    \n",
    "    N = 4\n",
    "    ind = np.arange(N) \n",
    "    width = 0.18\n",
    "\n",
    "    MNB_vals = [acc1[0],acc1[1],acc1[2],acc1[3]]\n",
    "    bar1 = plt.bar(ind, MNB_vals, width, color = 'r')\n",
    "\n",
    "    SGDC_vals = [acc2[0],acc2[1],acc2[2],acc2[3]]\n",
    "    bar2 = plt.bar(ind+width, SGDC_vals, width, color='g')\n",
    "\n",
    "    DTC_vals = [acc3[0],acc3[1],acc3[2],acc3[3]]\n",
    "    bar3 = plt.bar(ind+width*2, DTC_vals, width, color = 'b')\n",
    "\n",
    "    RFC_vals = [acc4[0],acc4[1],acc4[2],acc4[3]]\n",
    "    bar4 = plt.bar(ind+width*3, RFC_vals, width, color='y')\n",
    "    \n",
    "    MLPC_vals = [acc5[0],acc5[1],acc5[2],acc5[3]]\n",
    "    bar5 = plt.bar(ind+width*4, MLPC_vals, width, color='c')\n",
    "    \n",
    "    GBC_vals = [acc6[0],acc6[1],acc6[2],acc6[3]]\n",
    "    bar6 = plt.bar(ind+width*4, GBC_vals, width, color='m')\n",
    "    \n",
    "    ABC_vals = [acc7[0],acc7[1],acc7[2],acc7[3]]\n",
    "    bar7 = plt.bar(ind+width*4, ABC_vals, width, color='k')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(\"Accuracy Fields\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.title(\"Accuracies for 75-25 Split\")\n",
    "\n",
    "    plt.xticks(ind+width,['Testing Accuracy', 'Precision Score', 'Recall Score', 'F1-Score'])\n",
    "    plt.legend( (bar1, bar2, bar3, bar4, bar5, bar6, bar7), ('MNB', 'SGDC', 'DTC', 'RFC', 'MLPC', 'GBC', 'ABC') )\n",
    "    plt.show()\n",
    "    \n",
    "    return Result_table\n",
    "Main_GA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5 splits the possible accuracies are:\n",
      "Possible accuracies list for MultinomialNB(alpha=0.574365, fit_prior=False) are:[0.9716542750929368, 0.9941914498141264, 0.9825702997908436, 0.99070415988845, 0.976528003718336] \n",
      "Possible accuracies list for SGDClassifier() are:[0.9972118959107806, 0.9995353159851301, 1.0, 1.0, 0.9946548919358587] \n",
      "Possible accuracies list for DecisionTreeClassifier() are:[0.9990706319702602, 0.9997676579925651, 1.0, 1.0, 0.9941900999302812] \n",
      "Possible accuracies list for RandomForestClassifier() are:[1.0, 0.9997676579925651, 0.9997676039972112, 1.0, 0.9941900999302812] \n",
      "Possible accuracies list for MLPClassifier(hidden_layer_sizes=5, max_iter=10000, solver='lbfgs') are:[0.9962825278810409, 0.9990706319702602, 0.9993028119916337, 0.9995352079944225, 0.9948872879386474] \n",
      "###################################################################################################################################\n",
      "For 4 splits the possible accuracies are:\n",
      "Possible accuracies list for MultinomialNB(alpha=0.574365, fit_prior=False) are:[0.9671003717472119, 0.9877300613496932, 0.9929354898680052, 0.9782487451199108] \n",
      "Possible accuracies list for SGDClassifier() are:[0.9988847583643122, 1.0, 1.0, 0.9957241122885294] \n",
      "Possible accuracies list for DecisionTreeClassifier() are:[0.9996282527881041, 0.9998140918386317, 0.9998140918386317, 0.9940509388362149] \n",
      "Possible accuracies list for RandomForestClassifier() are:[1.0, 1.0, 0.9998140918386317, 0.9955382041271612] \n",
      "Possible accuracies list for MLPClassifier(hidden_layer_sizes=5, max_iter=10000, solver='lbfgs') are:[0.9998141263940521, 0.9998140918386317, 0.9994422755158952, 0.9957241122885294] \n",
      "###################################################################################################################################\n",
      "For 3 splits the possible accuracies are:\n",
      "Possible accuracies list for MultinomialNB(alpha=0.574365, fit_prior=False) are:[0.9757423672103722, 0.9888455103179029, 0.9793641940881205] \n",
      "Possible accuracies list for SGDClassifier() are:[0.9981876481249129, 0.9987451199107641, 0.9972113775794758] \n",
      "Possible accuracies list for DecisionTreeClassifier() are:[0.999721176634602, 0.9995817066369214, 0.9963747908533185] \n",
      "Possible accuracies list for RandomForestClassifier() are:[1.0, 0.9998605688789738, 0.9960959286112661] \n",
      "Possible accuracies list for MLPClassifier(hidden_layer_sizes=5, max_iter=10000, solver='lbfgs') are:[0.9988847065384079, 0.9976296709425544, 0.9974902398215282] \n",
      "###################################################################################################################################\n",
      "For 2 splits the possible accuracies are:\n"
     ]
    }
   ],
   "source": [
    "#Applying Stratified K_fold_Cross_Validation\n",
    "def Probable_SKF_scores(x):\n",
    "    skf=StratifiedKFold(n_splits=x,shuffle=False)\n",
    "    #Stratified K_Fold_spliting\n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        #pdb.set_trace()\n",
    "        #print(\"TRAIN:\", train_index,\"TEST:\",test_index)\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test = Tr_tokens[train_index], Tr_tokens[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            score=model.score(X_test, y_test)\n",
    "            if model==MNBC:MNBC_accu_stratified.append(score)    \n",
    "            elif model==SGDC:SGDC_accu_stratified.append(score)    \n",
    "            elif model==DTC:DTC_accu_stratified.append(score)\n",
    "            elif model==RFC:RFC_accu_stratified.append(score)\n",
    "            elif model==MLPC:MPLC_accu_stratified.append(score)\n",
    "    for model in models:\n",
    "        if model==MNBC:print(\"Possible accuracies list for {} are:{} \".format(model,MNBC_accu_stratified))\n",
    "        elif model==SGDC:print(\"Possible accuracies list for {} are:{} \".format(model,SGDC_accu_stratified))\n",
    "        elif model==DTC:print(\"Possible accuracies list for {} are:{} \".format(model,DTC_accu_stratified))\n",
    "        elif model==RFC:print(\"Possible accuracies list for {} are:{} \".format(model,RFC_accu_stratified))\n",
    "        elif model==MLPC:print(\"Possible accuracies list for {} are:{} \".format(model,MPLC_accu_stratified))\n",
    "    MNBC_accu_stratified.clear()\n",
    "    SGDC_accu_stratified.clear()\n",
    "    DTC_accu_stratified.clear()\n",
    "    RFC_accu_stratified.clear()\n",
    "    MPLC_accu_stratified.clear()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "for ele in split_list:\n",
    "    print('For {} splits the possible accuracies are:'.format(ele))\n",
    "    Probable_SKF_scores(ele)\n",
    "    print('###################################################################################################################################')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
